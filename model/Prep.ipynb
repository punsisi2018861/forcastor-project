{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e009d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\PunsisiK.LOITL-SE03\\AppData\\Local\\Temp/ipykernel_6524/2367096799.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data['InvoiceYearMonth'] = df_data['InvoiceDate'].map(lambda date: 100*date.year + date.month)\n",
      "C:\\Users\\PunsisiK.LOITL-SE03\\AppData\\Local\\Temp/ipykernel_6524/2367096799.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data['Revenue'] = df_data.UnitPrice * df_data.Quantity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NextPurchaseDay</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyCluster</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueCluster</th>\n",
       "      <th>OverallScore</th>\n",
       "      <th>Segment_High-Value</th>\n",
       "      <th>Segment_Low-Value</th>\n",
       "      <th>Segment_Mid-Value</th>\n",
       "      <th>NextPurchaseDayRange</th>\n",
       "      <th>predicted_transaction_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13085.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>1459.46</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18087.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>14411.62</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17519.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>5102.80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12362.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "      <td>3</td>\n",
       "      <td>5284.58</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15712.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>3</td>\n",
       "      <td>3467.46</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>16684.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>749</td>\n",
       "      <td>2</td>\n",
       "      <td>141502.25</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>12415.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>143269.29</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>17450.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>448</td>\n",
       "      <td>2</td>\n",
       "      <td>233579.39</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>14156.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>1</td>\n",
       "      <td>296564.69</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>14911.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11613</td>\n",
       "      <td>0</td>\n",
       "      <td>270248.53</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5314 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerID  NextPurchaseDay  Recency  RecencyCluster  Frequency  \\\n",
       "0        13085.0           9999.0       57               3         92   \n",
       "1        18087.0             46.0       44               3         95   \n",
       "2        17519.0            116.0       33               3        224   \n",
       "3        12362.0             40.0       12               3        275   \n",
       "4        15712.0             38.0        9               3        167   \n",
       "...          ...              ...      ...             ...        ...   \n",
       "5309     16684.0             67.0       33               3        749   \n",
       "5310     12415.0             14.0       13               3        990   \n",
       "5311     17450.0              1.0        0               3        448   \n",
       "5312     14156.0             17.0       14               3       4130   \n",
       "5313     14911.0              2.0        1               3      11613   \n",
       "\n",
       "      FrequencyCluster    Revenue  RevenueCluster  OverallScore  \\\n",
       "0                    3    1459.46               0             6   \n",
       "1                    3   14411.62               0             6   \n",
       "2                    3    5102.80               0             6   \n",
       "3                    3    5284.58               0             6   \n",
       "4                    3    3467.46               0             6   \n",
       "...                ...        ...             ...           ...   \n",
       "5309                 2  141502.25               2             7   \n",
       "5310                 2  143269.29               2             7   \n",
       "5311                 2  233579.39               2             7   \n",
       "5312                 1  296564.69               2             6   \n",
       "5313                 0  270248.53               2             5   \n",
       "\n",
       "      Segment_High-Value  Segment_Low-Value  Segment_Mid-Value  \\\n",
       "0                      0                  0                  1   \n",
       "1                      0                  0                  1   \n",
       "2                      0                  0                  1   \n",
       "3                      0                  0                  1   \n",
       "4                      0                  0                  1   \n",
       "...                  ...                ...                ...   \n",
       "5309                   1                  0                  0   \n",
       "5310                   1                  0                  0   \n",
       "5311                   1                  0                  0   \n",
       "5312                   0                  0                  1   \n",
       "5313                   0                  0                  1   \n",
       "\n",
       "      NextPurchaseDayRange  predicted_transaction_day  \n",
       "0                        0                          0  \n",
       "1                        1                          0  \n",
       "2                        0                          0  \n",
       "3                        1                          1  \n",
       "4                        1                          1  \n",
       "...                    ...                        ...  \n",
       "5309                     1                          2  \n",
       "5310                     2                          2  \n",
       "5311                     2                          2  \n",
       "5312                     2                          2  \n",
       "5313                     2                          2  \n",
       "\n",
       "[5314 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary Python libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Loading the data\n",
    "df = pd.read_csv('online_retail_II.csv',encoding='latin1')\n",
    "\n",
    "df.rename(columns={'Invoice':'InvoiceNo', 'Customer ID':'CustomerID', 'Price':'UnitPrice'}, inplace=True)\n",
    "\n",
    "df_data = df.dropna()\n",
    "df_data.InvoiceDate = pd.to_datetime(df_data.InvoiceDate)\n",
    "df_data['InvoiceYearMonth'] = df_data['InvoiceDate'].map(lambda date: 100*date.year + date.month)\n",
    "df_data['Revenue'] = df_data.UnitPrice * df_data.Quantity\n",
    "ctm_revenue = df_data.groupby('InvoiceYearMonth').Revenue.sum().reset_index()\n",
    "\n",
    "ctm_bhvr_dt = df_data[(df_data.InvoiceDate < pd.Timestamp(2011,9,1)) & \n",
    "      (df_data.InvoiceDate >= pd.Timestamp(2009,12,1))].reset_index(drop=True)\n",
    "\n",
    "\n",
    "ctm_next_quarter = df_data[(df_data.InvoiceDate < pd.Timestamp(2011,12,1)) & \n",
    "      (df_data.InvoiceDate >= pd.Timestamp(2011,9,1))].reset_index(drop=True)\n",
    "\n",
    "# Get the distinct customers in the dataframe ctm_bhvr_dt\n",
    "ctm_dt = pd.DataFrame(ctm_bhvr_dt['CustomerID'].unique())\n",
    "\n",
    "# Rename the column to CustomerID.\n",
    "ctm_dt.columns = ['CustomerID']\n",
    "\n",
    "# Create a dataframe with CustomerID and customers first purchase \n",
    "# date in ctm_next_quarter\n",
    "ctm_1st_purchase_in_next_quarter = ctm_next_quarter.groupby('CustomerID').InvoiceDate.min().reset_index()\n",
    "ctm_1st_purchase_in_next_quarter.columns = ['CustomerID','MinPurchaseDate']\n",
    "\n",
    "ctm_last_purchase_bhvr_dt = ctm_bhvr_dt.groupby('CustomerID').InvoiceDate.max().reset_index()\n",
    "ctm_last_purchase_bhvr_dt.columns = ['CustomerID','MaxPurchaseDate']\n",
    "\n",
    "# Merge two dataframes ctm_last_purchase_bhvr_dt and ctm_1st_purchase_in_next_quarter\n",
    "ctm_purchase_dates = pd.merge(ctm_last_purchase_bhvr_dt, ctm_1st_purchase_in_next_quarter, on='CustomerID', \n",
    "                              how='left')\n",
    "\n",
    "ctm_purchase_dates['NextPurchaseDay'] = (ctm_purchase_dates['MinPurchaseDate'] - ctm_purchase_dates['MaxPurchaseDate']).dt.days\n",
    "\n",
    "# merge with ctm_dt \n",
    "ctm_dt = pd.merge(ctm_dt, ctm_purchase_dates[['CustomerID','NextPurchaseDay']], on='CustomerID', how='left')\n",
    "\n",
    "ctm_dt = ctm_dt.fillna(9999)\n",
    "\n",
    "ctm_max_purchase = ctm_bhvr_dt.groupby('CustomerID').InvoiceDate.max().reset_index()\n",
    "ctm_max_purchase.columns = ['CustomerID','MaxPurchaseDate']\n",
    "\n",
    "# Find the recency in days \n",
    "ctm_max_purchase['Recency'] = (ctm_max_purchase['MaxPurchaseDate'].max() - ctm_max_purchase['MaxPurchaseDate']).dt.days\n",
    "\n",
    "# Merge the dataframes ctm_dt and ctm_max_purchase[['CustomerID', 'Recency']] on the CustomerID column.\n",
    "ctm_dt = pd.merge(ctm_dt, ctm_max_purchase[['CustomerID', 'Recency']], on='CustomerID')\n",
    "\n",
    "number_of_clusters = 4\n",
    "\n",
    "kmeans = KMeans(n_clusters=number_of_clusters)\n",
    "kmeans.fit(ctm_dt[['Recency']])\n",
    "ctm_dt['RecencyCluster'] = kmeans.predict(ctm_dt[['Recency']])\n",
    "\n",
    "def order_cluster(df, target_field_name, cluster_field_name, ascending):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        - df                  - pandas DataFrame\n",
    "        - target_field_name   - str - A column in the pandas DataFrame df\n",
    "        - cluster_field_name  - str - Expected to be a column in the pandas DataFrame df\n",
    "        - ascending           - Boolean\n",
    "        \n",
    "    OUTPUT:\n",
    "        - df_final            - pandas DataFrame with target_field_name and cluster_field_name as columns\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add the string \"new_\" to cluster_field_name\n",
    "    new_cluster_field_name = \"new_\" + cluster_field_name\n",
    "    \n",
    "    # Create a new dataframe by grouping the input dataframe by cluster_field_name and extract target_field_name \n",
    "    # and find the mean\n",
    "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
    "    \n",
    "    # Sort the new dataframe df_new, by target_field_name in descending order\n",
    "    df_new = df_new.sort_values(by=target_field_name, ascending=ascending).reset_index(drop=True)\n",
    "    \n",
    "    # Create a new column in df_new with column name index and assign it values to df_new.index\n",
    "    df_new[\"index\"] = df_new.index\n",
    "    \n",
    "    # Create a new dataframe by merging input dataframe df and part of the columns of df_new based on \n",
    "    # cluster_field_name\n",
    "    df_final = pd.merge(df, df_new[[cluster_field_name, \"index\"]], on=cluster_field_name)\n",
    "    \n",
    "    # Update the dataframe df_final by deleting the column cluster_field_name\n",
    "    df_final = df_final.drop([cluster_field_name], axis=1)\n",
    "    \n",
    "    # Rename the column index to cluster_field_name\n",
    "    df_final = df_final.rename(columns={\"index\": cluster_field_name})\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "ctm_dt = order_cluster(ctm_dt, 'Recency', 'RecencyCluster', False)\n",
    "\n",
    "#get order counts for each user and create a dataframe with it\n",
    "ctm_frequency = df_data.groupby('CustomerID').InvoiceDate.count().reset_index()\n",
    "ctm_frequency.columns = ['CustomerID','Frequency']\n",
    "\n",
    "#add this data to our main ctm_dt\n",
    "ctm_dt = pd.merge(ctm_dt, ctm_frequency, on='CustomerID')\n",
    "\n",
    "kmeans = KMeans(n_clusters=number_of_clusters)\n",
    "kmeans.fit(ctm_dt[['Frequency']])\n",
    "ctm_dt['FrequencyCluster'] = kmeans.predict(ctm_dt[['Frequency']])\n",
    "\n",
    "ctm_dt = order_cluster(ctm_dt, 'Frequency', 'FrequencyCluster', False)\n",
    "\n",
    "ctm_revenue = df_data.groupby('CustomerID').Revenue.sum().reset_index()\n",
    "\n",
    "#merge it with our ctm_dt\n",
    "ctm_dt = pd.merge(ctm_dt, ctm_revenue, on='CustomerID')\n",
    "\n",
    "#apply clustering\n",
    "kmeans = KMeans(n_clusters=number_of_clusters)\n",
    "kmeans.fit(ctm_dt[['Revenue']])\n",
    "ctm_dt['RevenueCluster'] = kmeans.predict(ctm_dt[['Revenue']])\n",
    "\n",
    "#order the cluster numbers\n",
    "ctm_dt = order_cluster(ctm_dt, 'Revenue', 'RevenueCluster', True)\n",
    "\n",
    "#calculate overall score and use mean() to see details\n",
    "ctm_dt['OverallScore'] = ctm_dt['RecencyCluster'] + ctm_dt['FrequencyCluster'] + ctm_dt['RevenueCluster']\n",
    "ctm_dt['Segment'] = 'Low-Value'\n",
    "ctm_dt.loc[ctm_dt['OverallScore'] > 4, 'Segment'] = 'Mid-Value'\n",
    "ctm_dt.loc[ctm_dt['OverallScore'] > 6, 'Segment'] = 'High-Value'\n",
    "\n",
    "#create ctm_class as a copy of ctm_dt before applying get_dummies\n",
    "ctm_class = ctm_dt.copy()\n",
    "ctm_class = pd.get_dummies(ctm_class)\n",
    "ctm_class.head()\n",
    "\n",
    "ctm_class['NextPurchaseDayRange'] = 2  ## first week\n",
    "ctm_class.loc[ctm_class.NextPurchaseDay>30,'NextPurchaseDayRange'] = 1 # 4th week\n",
    "ctm_class.loc[ctm_class.NextPurchaseDay>90,'NextPurchaseDayRange'] = 0 # more than 3 months\n",
    "\n",
    "user_df = ctm_class.copy()\n",
    "ctm_class = ctm_class.drop('NextPurchaseDay', axis=1)\n",
    "ctm_class = ctm_class.drop('CustomerID', axis=1)\n",
    "ctm_class = ctm_class.drop('NextPurchaseDayRange', axis=1)\n",
    "# y = to_categorical(y)\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "X = sc.fit_transform(ctm_class)\n",
    "\n",
    "# model= joblib.load('txnDayPredictionModel.h5')\n",
    "model = keras.models.load_model (\"txnDayPredictionModel.h5\") \n",
    "pred= model.predict(X)\n",
    "\n",
    "# Create a new dataframe with the user ID column from tx_class\n",
    "predictions_df = pd.DataFrame(user_df['CustomerID'])\n",
    "\n",
    "# Add the transaction day with the highest probability as a column to the predictions_df\n",
    "predictions_df['predicted_transaction_day'] = np.argmax(pred, axis=1)\n",
    "\n",
    "# Merge the predictions_df with the tx_class dataframe based on the user ID column\n",
    "merged_df = pd.merge(user_df, predictions_df, on='CustomerID')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02acde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
